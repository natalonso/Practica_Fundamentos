---
title: "Practica Fundamentos Casas"
author: "Natalia Alonso, Beatriz Martín y Susana Albarran"
date: "2/12/2019"

output: bookdown::gitbook
---

#  Introducción

Los datos que se van a analizar en este proyecto han sido obtenidos desde Kaggle. Contienen precios de casas que fueron vendidas desde mayo de 2014 hasta mayo de 2015 en **King County** que es un condado ubicado en el estado estadounidense de Washington. 

Se van a seguir los siguientes pasos:

 - Objetivo del estudio.  
 - Descripción de los datos.
 - Train, test y validación.
 - Análisis exploratorio de datos.
 - Transformación de variables cuantitativas. 
 - Procesado de variables cualitativas.
 - Detección, tratamiento e imputación de datos faltantes.
 - Selección de Variables.
 - Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple.


# Objetivo del estudio

Lo que queremos hacer con estos datos es crear un modelo para poder predecir los precios de las casas en King County, basándose en las variables que se incluyen en el dataset con el que se va a trabajar.

# Descripción de los datos

Los datos con los que se van a trabajar han sido extraidos de Kaggle: https://www.kaggle.com/harlfoxem/housesalesprediction

A continuación se van a describir las variables:

 **1.- Id**: es un identificador para cada casa que se ha vendido.  

 **2.- Date**: fecha de venta de la casa.  

 **3.- Price**: precio de venta de la casa.  

 **4.- Bedrooms**: núnero de habitaciones que tiene la casa.  

 **5.- Bathrooms**: número de cuartos de baño. Es importante destacar que 0.5 cuenta como baño que tiene ducha y no bañera. Esto lo tratamos con más detalle en el apartado de análisis de datos.

 **6.- sqft_living**: pies cuadrados habitables.  

 **7.- sqft_lot**: pies cuadrados del terreno de la parcela.  

 **8.- Floors**: número de plantas. Hay que tener en cuenta que se contabiliza 0.5 plantas cuando una planta no tiene todo el espacio construido. Por ejemplo la buhardilla.  

 **9.- Waterfront**: vistas al agua. Es una variable Dummy que nos dice si las casas tienen o no vistas al agua. 

 **10.- View**: vistas de la casa. Es una variable que toma valores de 0 a 4.

 **11.- Condition**: condiciones de la casa. Toma valores de 1 a 5. 

 **12.- Grade**: grados de calidad en la construccion. Toma valores de 1 a 13.

 **13.- sqft_above**: pies cuadrados por encima del suelo.  

 **14.- sqft_basement**: pies cuadrados del sótano.

 **15.- yr_built**: año de construcción.

 **16.- yr_renovated**: año en el que la casa se ha realizado.

 **17.- Zipcode**: en qué área se encuentra la casa. 

 **18.- lat**: latitud.

 **19.- long**: longitud.

 **20.- sqft_living15**: pies cuadrados del interior de las 15 casas más cercanas.

 **21.- sqft_lot15**: pies cuadrados del terreno de las 15 casas más cercanas.

A continuación, se van a cargar los datos en R: 

```{r lectura_datos, include=FALSE}

#datos <- read.csv("C:/Users/natal/OneDrive/Documentos/0_MIS_DOCUMENTOS/2.MÁSTER/2_Curso_2019-2020/Primer_Cuatrimestre/2.Fundamentos_de_Análisis/BloqueIV_Métodos/Práctica final/git/kc_house_data.csv")

datos <- read.csv("C:/Users/Beatriz/Desktop/Máster/1er trimestre/Fundamentos/Parte 4_Métodos de Análisis de datos/Prac_git/kc_house_data.csv")


#datos <- read.csv("C:/Users/susi_/Desktop/R/Practica_Fundamentos_R/Repositorios git/kc_house_data.csv")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lattice)
library(dplyr)
library(VIM)
library(mice)
library(DMwR2)
library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)
library(GGally)
library(ggplot2)
library(corrplot)
library(vcd)
library(DT)
library(gridExtra)
library(jpeg)
library(car)
library(leaflet)
```

# Train, test y validación

Lo primero que se va a relizar es separar los datos en los 3 conjuntos de datos fundamentales:  

-  Conjunto de datos de **entrenamiento**: en nuestro estudio **datos_train**.70%
-  Conjunto de datos de **validación**: en nuestro estudio **datos_validacion**.15%
-  Conjunto de datos de **test**: en nuestro estudia **datos_test**. 15%

```{r}

num_total=nrow(datos)
set.seed(122556) #reproductividad

# 70% para train
indices_train = sample(1:num_total, .7*num_total)
datos_train = datos[indices_train,]

# 15% para test
indices=seq(1:num_total)
indices_test=indices[-indices_train]
indices_test1 = sample(indices_test, .15*num_total)
datos_test = datos[indices_test1,]

# 15% para validacion
indices_validacion=indices[c(-indices_train,-indices_test1)]
datos_validacion=datos[indices_validacion,]

```


# Análisis exploratorio de datos

Para el análisis de los datos, se han dividido las variables en tres categorías:

  -**Variables de características de las casas**: bedrooms, bathrooms,floors, sqft_living, sqft_lot,  
  
  sqft_above, sqfr_basement, sqft_living15, sqft_lot15.
  
  -**Variables de calidad**: waterfront, view, condition, grade, yr_built, yr_renovated. 
  
  -**Variables de localización**: zipcode, lat, long.


Visualizamos una muestra de los datos:

```{r}
datatable(head(datos_train))   
```


Se muestra un resumen de los datos con los que se va a trabajar:

```{r}
str(datos_train)
summary(datos_train)
```


## Caracteristicas de las casas

A continuación, se va a realizar un análisis exploratorio para ver cómo se comporta cada variable:  

**-Variable Price**: es numérica, es la variable respuesta del estudio:

```{r}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=price)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

```

Se observa que el precio de las casas es asimétrico, tiene mayor frecuencia hacia el lado izquierdo de la distribución. En estos casos se suele hacer una **transformación logarítmica**.


```{r}

datos_train$log_price<- log10(datos_train$price)

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=log_price)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

```
 
Como se observa con la transformación logarítmica de la variable price ('log_price') obtenemos una distribución más asimétrica. 


**-Variable Bedroom**: es de tipo entero.

```{r}
table(datos_train$bedrooms)
class(datos_train$bedrooms) 
```

```{r}

#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p1<-ggplot(datos_train, aes(x=bedrooms)) + geom_histogram(colour="black", bins =30,fill="tomato")

p2<-ggplot(datos_train, aes(x=as.factor(bedrooms), y=log_price, fill=as.factor(bedrooms))) + geom_boxplot()+
labs(x="bedrooms")+theme(legend.position="none")

grid.arrange(p1, p2, nrow = 1)
              

```

Al generar la tabla y los gráficos se observa que hay casas con **0** habitaciones y **33** , más adelante tendremos que ver qué ocurre con estos datos.

Podemos decir que segun aumenta el número de habitaciones aumenta el precio de las casas.

 
**-Variable bathrooms**: es de tipo entero.

```{r}
table(datos_train$bathrooms)
```

La variable Bathrooms puede tomar valores decimales de 0.25 en 0.25. El número de baños se contabiliza por las piezas, cada baño completo tiene 4 piezas. 

-Baño (4 piezas) -> Inodoro, lavabo, bañera y ducha.(1 unidad) -Baño completo

-Baño (3 piezas) -> Inodoro, lavabo y ducha. (0.75 unidad) - Baño con ducha  

-Baño (2 piezas) -> Inodoro y lavabo. (0.5 unidad) - Aseo

-Baño (1 pieza) -> Inodoro (0.25 unidad) - Aseo

Vamos a agrupar los baños del siguiente modo:

-Valores: 0.25, 0.5, 0.75, 1 = 1 baño.

-Valores: 1,25, 1,5, 1.75, 2 = 2 baños.

Y así hasta 8 baños que es el número máximo.


```{r}
datos_train$bathrooms <- as.numeric(datos_train$bathrooms)
datos_train$bathrooms_group <- cut(datos_train$bathrooms,breaks = c(-1,0.25,1,2,3,4,5,6,7,8),labels=c(0,1,2,3,4,5,6,7,8))


table(datos_train$bathrooms_group)

#Dibujamos como queda categorizada enfrentada con la variable "price" ya transformada:
ggplot(datos_train, aes(x=as.factor(datos_train$bathrooms_group), y=log_price, fill=as.factor(datos_train$bathrooms_group))) + geom_boxplot()+
labs(x="bathrooms_group")+theme(legend.position="none")

```


Se observa que hay 7 casas con cero baños, puede que estos datos se tengan que tratar más adelante.

**-Variable sqft_living**: es numérica. Se va a pintar un histograma y la densidad para ver su comportamiento. 

```{r}

#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p5<-ggplot(datos_train, aes(x=sqft_living)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

p6<-ggplot(datos_train, aes(sqft_living, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "red") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 

grid.arrange(p5,p6, nrow=1)
```

En este segundo gráfico se ha enfrentado con la variable price, se ve que hay una relación creciente, a medida que aumentan los pies cuadrados aumenta el precio de las casas.

Se va a realizar una transformación logarítmica para la variable sqft_living:

```{r}
datos_train$log_sqft_living<- log10(datos_train$sqft_living)

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=log_sqft_living)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

```
```{r}
ggplot(datos_train, aes(log_sqft_living, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "red") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 
```


**- Variable  sqft_lot**: pies cuadrados del terreno. Es variable numérica, vamos a estudiar como se comporta:

Al igual que el precio de la vivienda, no es simétrica y los pies cudrados de las casas, están concetrados a la izquierda. Por lo que se podría realizar una transformación logarítmica.

```{r}

p7<-ggplot(datos_train, aes(x=sqft_lot)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="tomato") 

p8<-ggplot(datos_train, aes(sqft_lot, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "blue") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 

grid.arrange(p7,p8, nrow=1)

```


**- Variable  floors**: Número de plantas de la casa,hay que tener en cuenta que se contabiliza 0.5 plantas cuando una planta no tiene todo el espacio construido. (Ejem: Buhardilla). Es numérica.

```{r}

#datos_train$floors<-as.factor(datos_train$floors)
table(datos_train$floors)

``` 
```{r}
#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p9<-ggplot(datos_train, aes(x=floors)) + geom_histogram(colour="black", bins =30,fill="tomato")


p10<-ggplot(datos_train, aes(x=as.factor(floors), y=log_price, fill=as.factor(floors))) + geom_boxplot()+
labs(x="floors")+theme(legend.position="none")

grid.arrange(p9,p10, nrow=1)
```


**- Variable sqtft_basement **: pies cuadrados del sótano. Es numérica.  

```{r}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=sqft_basement)) + geom_histogram(bins=30, colour="black", fill="#E1AF00") 

```

Se observa que alrededor de unas 12.500 no tienen sótano, la vamos a transformar del siguiente modo:

- 0 = casas que no tienen sótano.

- 1 = casas que sí tienen sótano.

```{r}
datos_train$sqft_basement_cat <- as.numeric(datos_train$sqft_basement)
datos_train$sqft_basement_cat <- cut(datos_train$sqft_basement_cat,breaks = c(-1,0,6000),labels=c(0,1))
table(datos_train$sqft_basement_cat)
```
``` {r}
ggplot(datos_train, aes(x=log_price, fill= as.factor(sqft_basement_cat))) + geom_density(alpha=.3)

```

**- Variable sqft_living15 **: pies cuadrados de la zona habitable de la casa de los 15 vecinos más cercanos. Es numérica.


```{r}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=sqft_living15)) + geom_histogram(bins=30, colour="black", fill="#E1AF00") 


```


**- Variable sqft_lot15**, pies cuadrados del exterior de la casa de los 15 vecinos más cercanos.Es numérica.

```{r}

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=sqft_lot15)) + geom_histogram(bins=30, colour="black", fill="#E1AF00") 


```


## Calidad

**- Variable waterfront**: Es categórica.Toma valores 0 y 1 (Dummy).  

 - 0 = no tiene vistas al agua (Se ha confirmado este dato con la latitud y longitud de la casa en google maps.)
 - 1 = tiene vistas al agua.

```{r}
#datos_train$waterfront<-as.factor(datos_train$waterfront)
table(datos_train$waterfront)

```

```{r}
#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
#p11<-ggplot(datos_train, aes(x=waterfront)) + geom_histogram(colour="black", bins =30,fill="tomato")


ggplot(datos_train, aes(x=log_price, fill=as.factor(waterfront))) + geom_histogram(binwidth=0.1, alpha=.5, position="identity")

```


Se observa que casi todas las casas no tienen vistas al agua y que las casas que tienen vistas son más caras respecto de las que no tienen vistas al agua.
 
**- Variable view**: Es de tipo entero.Toma valores de 1 a 4. 

```{r}

table(datos_train$view)
#datos_train$view <- as.factor(datos_train$view)

```

```{r}
#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p11<-ggplot(datos_train, aes(x=view)) + geom_histogram(colour="black", bins =30,fill="tomato")


p12<-ggplot(datos_train, aes(x=as.factor(view), y=log_price, fill=as.factor(view))) + geom_boxplot()+
labs(x="view")+theme(legend.position="none")

grid.arrange(p11,p12, nrow=1)

```

Se observa que la mayoría de las casas no tienen buenas vistas y que las casas que tienen vistas son más caras respeto de las que no tienen vistas al agua.


**- Variable condition**: Es de tipo entero. Toma valores de 1 a 5.

```{r}
#datos_train$condition <- as.factor(datos_train$condition)
table(datos_train$condition)

```

```{r}
#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p13<-ggplot(datos_train, aes(x=condition)) + geom_histogram(colour="black", bins =30,fill="tomato")

p14<-ggplot(datos_train, aes(x=as.factor(condition), y=log_price, fill=as.factor(condition))) + geom_boxplot()+
labs(x="condition")+theme(legend.position="none")

grid.arrange(p13,p14, nrow=1)
```


**- Variable grade**: Es de tipo entero. Mide la calidad de la construcción. Toma valores de 1 a 13.

```{r}

table(datos_train$grade)

```
```{r}
#(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p14<-ggplot(datos_train, aes(x=grade)) + geom_histogram(colour="black", bins =30,fill="tomato")


p15<-ggplot(datos_train, aes(x=as.factor(grade), y=log_price, fill=as.factor(grade))) + geom_boxplot()+
labs(x="grade")+theme(legend.position="none")

grid.arrange(p14,p15, nrow=1)
```

Cuando se enfrenta con la variable precio se ve que a mayor grado es mayor el precio de las casas.

Se va a volver a categorizar del siguiente modo:

 - Valores de 1-4 = calidad baja se va a categorizar con valor 0
 - Valores de 5-9 = calidad media se va a categorizar con valor 1
 - Valores de 10-13 = calidad alta se va a categorizar con valor 2
 
```{r}
datos_train$grade<-as.numeric(datos_train$grade)
datos_train$grade_categ <- cut(datos_train$grade, breaks = c(0,4,9,13), labels = c(0,1,2))

table(datos_train$grade_categ)
```
```{r}
#Dibujamos como queda categorizada enfrentada con la variable "price"
ggplot(datos_train, aes(x=as.factor(datos_train$grade_categ), y=log_price, fill=as.factor(datos_train$grade_categ))) + geom_boxplot() + labs(x="grade_categ")+theme(legend.position="none")
```



**- sqft_above  **: Es numérica. Pies cuadrados por encima del suelo. Esta variable hay que aclarar que es la diferencia entre sqft_living y sqft_basement.

```{r}

#options(scipen=999)
#options(repr.plot.width=6, repr.plot.height=3,align="center")
p16<-ggplot(datos_train, aes(x=sqft_above)) + geom_histogram(aes(y=..density..), bins=30, colour="black", fill="white") + geom_density(alpha=.3, fill="#E1AF00")

p17<-ggplot(datos_train, aes(sqft_above, log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = F, method = "lm", color = "blue") +
  scale_y_continuous(breaks = seq(0,8000000, by = 1000000)) 

grid.arrange(p16,p17, nrow=1)

```


**- yr_built  **: Año de construcción de la casa. (1900-2015)

```{r}
table(datos_train$yr_built)

options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=yr_built)) + geom_histogram(colour="black",bins=30, fill="#E1AF00") 

```

**- Variable yr_renovated  **: Año en el que la casa tuvo una ´renovación´.

```{r}
table(datos_train$yr_renovated)


options(scipen=999)
options(repr.plot.width=6, repr.plot.height=3,align="center")
ggplot(datos_train, aes(x=yr_renovated)) + geom_histogram(colour="black",bins=30, fill="#E1AF00") 


```


Se observa que hay un año "0" y entendemos que son casas que no han tenido ningún tipo de renovación. Se podría categorizar como:
 
 - yr_renovated = 0 , No ha tenido ninguna renovación
 - yr_renovated = resto de años , Sí ha tenido renovación


```{r}
table(datos_train$yr_renovated)
datos_train$yr_renovated_catg <-cut(datos_train$yr_renovated, breaks=c(-0.5,1933, 2015), labels= c("0","1"))

table(datos_train$yr_renovated_catg)

```

```{r}
#Dibujamos como queda categorizada enfrentada con la variable "price"
ggplot(datos_train, aes(x=as.factor(datos_train$yr_renovated_catg), y=log_price, fill=as.factor(datos_train$yr_renovated_catg))) + geom_boxplot() + labs(x="Renovación/no renovación")+theme(legend.position="none")
```


## Localización

```{r}
ggpairs(datos_train,columns=c(3,17:19),mapping = aes(color = "red") )

```


**- Variable zipcode **: En qué área se encuentra la casa (Son códigos postales de Seattle). Es categórica.  


```{r}
#datos_train$zipcode<-as.factor(datos_train$zipcode)
table(datos_train$zipcode)

```


**- Variable lat y long **: indica la ubicación de la casa, latitud, longitud. 

A lo mejor se puede dibujar una gráfica dependiendo de la zona geográfica y el precio de las casas.

```{r}
#datos_train$Pricegroup<-cut(datos_train$price, c(-1,250e3,500e3,750e3,1e6,2e6,999e6))
datos_train$Pricegroup<-cut(datos_train$price, c(0,250000,500000,750000,1000000,2000000,10000000))

center_lon = median(datos_train$long,na.rm = TRUE)
center_lat = median(datos_train$lat,na.rm = TRUE)

factpal <- colorFactor(c("black","blue","yellow","orange","pink","red"), 
                       datos_train$Pricegroup )

leaflet(datos_train) %>% addProviderTiles("Esri.NatGeoWorldMap") %>%
  addCircles(lng = ~long, lat = ~lat,
             color = ~factpal(Pricegroup))  %>%
  # controls
  setView(lng=center_lon, lat=center_lat,zoom = 12) %>%

  addLegend("bottomright", pal = factpal , values = ~Pricegroup,
            title = "Precio de las casas por localización",
            opacity = 1)
```


```{r}
#ggpairs(datos_train,columns=c(3,9:12,15,16),mapping = aes(color = "red") )
#ggpairs(datos_train,columns=c(3,13:16),mapping = aes(color = "red") )


```


# Detección, tratamiento e imputación de datos faltantes

En nuestros datos no tenemos datos faltantes, pero gracias al análisis exploratorio previamente hecho nos hemos dado cuenta de que tenemos outliers en diferentes variables.

```{r}
#Contar el total de NAs en la base de datos
sum(is.na(datos_train))

```

En el caso de la variable **Bedrooms** hemos visto que hay 13 casas con 0 habitaciones y una con 33. Como en nuestro estudio no tenemos datos faltantes, lo que vamos a hacer a continuación es suponer que la casa con 33 habitaciones es un NA.

Primero nos vamos a crear un dataframe auxiliar para probar diferentes métodos y poder tomar una decisión.

```{r}
datos_train$posicion<-c(1:nrow(datos_train))

indice_hab33 <- datos_train[datos_train$bedrooms==33,]$posicion
indice_hab33

datos_train_aux1 <- datos_train

datos_train_aux1$bedrooms[datos_train_aux1$bedrooms==33] <-NA
#sum(is.na(datos_train_aux))

datos_train_aux2 <- datos_train

datos_train_aux2$bedrooms[datos_train_aux2$bedrooms==33] <-NA

datos_train_aux3 <- datos_train

datos_train_aux3$bedrooms[datos_train_aux3$bedrooms==33] <-NA
```

Ahora lo vamos a imputar mediante regresión simple:

```{r}

datos_mice<-datos_train_aux1[,c(3:12,15,16)]

#dist(datos_train[8742,18:19])

# Imputación simple, regresión ordinaria:

imp_1 = mice(datos_mice, method = "norm.predict", m=1) # Cálculo método de imputación

datostrain_mice = complete(imp_1)  # Imputación de valores

datostrain_mice$posicion<-c(1:nrow(datostrain_mice))

#Ha imputado:
datostrain_mice[datostrain_mice$posicion == indice_hab33,]$bedrooms

#floor(datostrain_mice[datostrain_mice$posicion == indice_hab33,]$bedrooms)

```

Ha imputado con el valor 3.208425. Como las habitaciones toman valores discretos, nos quedamos con 3 habitaciones.


```{r}
# SI QUEREMOS EJECUTAR ESTO HAY QUE HACER EL FLOOR() DE ARRIBA PARA QUE NO SALGA DECIMAL LA HABITACION
#sólo hago los gráficos para ver el valor que ha imputado
# ggplot(datostrain_mice, aes(x=as.factor(bedrooms), y=price, fill=bedrooms)) + geom_boxplot() + guides(fill=FALSE)
# Para imputar los datos faltantes o erróneos ver qué técnica usar:
# datos$bedrooms[datos$bedrooms==0] = mean(datos$bedrooms)
# datos$bedrooms[datos$bedrooms==33] = mean(datos$bedrooms)
# Repasar qué técnicas usar

```
```{r}
datos_mice2<-datos_train_aux2[,c(3:12,15,16)]
```

```{r}
# Imputación multiple, regresión estocástica:

imp_2 = mice(datos_mice2, method = "norm.nob", seed=1234)# Cálculo método de imputación

datostrain_mice2 = complete(imp_2)  # Imputación de valores sustiyuye 33

datostrain_mice2$posicion<-c(1:nrow(datostrain_mice2))

#Ha imputado:
datostrain_mice2[datostrain_mice2$posicion == indice_hab33,]$bedrooms

```

En este caso el valor que toma es 3.211892, por lo que coincide con el anterior en que son 3 habitaciones lo que tenemos que imputar.

```{r}

#sólo hago los gráficos para ver el valor que ha imputado 
# 
# ggplot(datostrain_mice2, aes(x=as.factor(bedrooms), y=price, fill=bedrooms)) + geom_boxplot() + guides(fill=FALSE)

```


Otro modo de imputar el dato faltante es compararlo con los vecinos más cercanos.Para ello lo que hemos ehcho es calcular la diferencia entre la latitud de la casa con 33 habitaciones con el resto y lo mismo para la longitud. Luego hemos sumado esas diferenecias y nos hemos quedado con las 15 distancias más pequeñas.

```{r}
datos_train_aux3$diferencia_lat<- abs(datos_train$lat[datos_train$bedrooms==33]-datos_train[,18])

datos_train_aux3$diferencia_long<- abs(datos_train$long[datos_train$bedrooms==33]-datos_train[,19])

datos_train_aux3$diferencia_total <- datos_train_aux3$diferencia_lat+datos_train_aux3$diferencia_long

casas_mas_cercanas <- as.data.frame(sort(datos_train_aux3$diferencia_total,index.return=TRUE))
indices_casas_cercanas <- casas_mas_cercanas$ix[2:16] # la primera no se coge porque es la propia casa con 33 habitaciones

mean(datos_train_aux3$bedrooms[indices_casas_cercanas])

```

El resultado que obtenemos en este caso es 3.333333. Al igual que en los métodos anteriores, la imputación sería de 3 habitaciones.

Por lo que finalmente imputamos que esa casa tiene 3 habitaciones.

```{r}
datos_train[datos_train$posicion == indice_hab33,]$bedrooms = 3
```


Con el Boxplot observamos lo siguiente:  

- La casa que tiene **33 habitaciones** tiene menos pies cuadrados que el resto de las casas, por lo que confirma que es un dato erróneo.(Podríamos elimarlo)  

- Las casas que tienen **0 habitaciones** (13 casas), tienen más pies cuadrados, por lo que sería también un dato erróneo, ya que revisando en google maps por las corrdenadas longitud y la latitud son casas que incluso tienen varias plantas.

En el caso de la variable *Bathroom* hemos visto que hay 10 casas con 0 baños. Vamos a comparar la variable número de baños con los pies cuadrados habitables. Porque con un razonamiento lógico cuanto más espacio más número de baños.

```{r}
ggplot(datos_train, aes(x=as.factor(bathrooms), y=log_price, fill=bathrooms)) + geom_boxplot() + guides(fill=FALSE)
```

```{r}

ggplot(datos_train, aes(x=as.factor(floors), y=log_price, fill=floors)) + geom_boxplot() + guides(fill=FALSE)

```

```{r}

#imagen=paste("C:/Users/natal/OneDrive/Documentos/0_MIS_DOCUMENTOS/2.MÁSTER/2_Curso_2019-2020/Primer_Cuatrimestre/2.Fundamentos_de_Análisis/BloqueIV_Métodos/Práctica final/git","Casa_33habitaciones_v2.jpeg")
#knitr::include_graphics(imagen)

```

# Selección de variable

Para hacer una selección de variables ya hemos estudiado como se comportan con la variable precio. A continuación se va a realizar una matriz de correlaciones para terminar de decidir con qué variables nos quedamos:

```{r}
datos_train_cor <- datos_train[,3:21]
correlation_matrix <- cor(datos_train_cor, method = "spearman")
corrplot(correlation_matrix, method = "color", tl.srt=45, addCoef.col ="black", number.cex =0.6,
         tl.cex = 0.7,tl.col="black", type= "upper")

datos_train_cor2 <- datos_train[,c(22,4,5,24,7:21)]
correlation_matrix2 <- cor(datos_train_cor2, method = "spearman")
corrplot(correlation_matrix2, method = "color", tl.srt=45, addCoef.col ="black", number.cex =0.6,
         tl.cex = 0.7,tl.col="black", type= "upper")

```



# Ajuste, interpretación y diagnosis del modelo de regresión lineal múltiple


```{r}

datos_train_model <- datos_train[c(1,22,4,23,7,24,8:11,26,13,14,18:21,25,27)]

datos_train_model$waterfront<-as.factor(datos_train_model$waterfront)
datos_train_model$view<-as.factor(datos_train_model$view)
datos_train_model$condition<-as.factor(datos_train_model$condition)

datos_train_model$bathrooms_group<-as.numeric(datos_train_model$bathrooms_group)

library(scales)

#Ahora reescalamos un variable de la base de datos

kable(rescale(datos_train_model$bedrooms))
kable(rescale(datos_train_model$bathrooms_group))

kable(rescale(datos_train_model$log_sqft_living))
kable(rescale(datos_train_model$sqft_lot))
kable(rescale(datos_train_model$floors))
kable(rescale(datos_train_model$sqft_above))
kable(rescale(datos_train_model$sqft_basement_cat))
kable(rescale(datos_train_model$sqft_living15))
kable(rescale(datos_train_model$sqft_lot15))


# Vamos a crear un data_frame nuevo limpio: (????)

modelo6<-lm(formula = log_price ~ log_sqft_living, data = datos_train_model)
summary(modelo6)
# R_squared = 0.46

modelo5<-lm(formula = log_price ~ log_sqft_living + bathrooms_group, data = datos_train_model)
summary(modelo5)
# R_squared = 0.46

modelo4<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ, data = datos_train_model)
summary(modelo4)
# R_squared = 0.5

modelo3<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + floors + yr_renovated_catg, data = datos_train_model)
summary(modelo3)
# R_squared = 0.67

modelo3<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + yr_built, data = datos_train_model)
summary(modelo3)
# R_squared = 0.68

modelo3<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + waterfront, data = datos_train_model)
summary(modelo3)
# R_squared = 0.68

modelo3<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + waterfront + view, data = datos_train_model)
summary(modelo3)
# R_squared = 0.70

modelo3<-lm(formula = log_price ~ log_sqft_living + bathrooms_group + grade_categ + lat + floors + view, data = datos_train_model)
summary(modelo3)
# R_squared = 0.7

vif(modelo3) #nos da un factor que mida la inflacion de la varianza por tener variable co-lineales

# usamos una seleccion automatica de variables para comparar la evaluacion del modelo
regfit_full <- leaps::regsubsets(log_price~., datos_train_model[c(2:5,7,10:13,16:21)]) #Best subset
reg_sum
reg_sum <- summary(regfit_full)
coef(regfit_full, 6)



# modelo con las caracteristicas de la seleccion automatica Best subset
modelo3<-lm(formula = log_price ~ floors + waterfront+ yr_built + lat + log_sqft_living + grade_categ, data = datos_train_model)
summary(modelo3)
# R_squared = 0.7



# modelo regularización lasso
x <- model.matrix(log_price~., datos_train_model[c(2:5,7,10:13,16:21)])
x

y <- datos_train_model$log_price
y

library(glmnet)

set.seed(1234)
cv_result <- cv.glmnet(x,y,alpha=1)
cv_result

plot(cv_result)

best_lam <- cv_result$lambda.min
best_lam

out <- glmnet(x,y,alpha=1,lambda = best_lam)
out

lasso_coef <- predict(out,type="coefficients",s=best_lam)[1:20,]
lasso_coef[lasso_coef!=0]
lasso_coef


first_six <- max(which(cv_result$nzero == 6))
first_six

my_lam <- cv_result$lambda[first_six]
my_lam

out_six <- glmnet(x,y,alpha=1,lambda = first_six)
out_six

lasso_coef_six <- predict(out_six,type="coefficients")[1:20,]
lasso_coef_six

lasso_coef_six[lasso_coef_six!=0]
lasso_coef_six





```

# Test

```{r}

# TRANSFORMAR LOS DATOS DE TEST CONFORME A LO QUE HABÍAMOS DECIDIDO EN TRAIN:


predict(modelo3, newdata = datos_test)

```

